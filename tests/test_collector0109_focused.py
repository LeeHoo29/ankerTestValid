#!/usr/bin/env python3
"""
collector0109 å­˜å‚¨è´¦æˆ·ä¸“é¡¹æµ‹è¯•
ä¸“é—¨æµ‹è¯•ç‰¹å®šè·¯å¾„ä¸‹çš„è§£ææ–‡ä»¶
"""
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from src.azure_resource_reader import AzureResourceReader
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_collector0109_connection():
    """æµ‹è¯•collector0109è¿æ¥"""
    print("ğŸ” æµ‹è¯•collector0109å­˜å‚¨è´¦æˆ·è¿æ¥")
    print("=" * 60)
    
    try:
        reader = AzureResourceReader('collector0109')
        print("âœ… collector0109è¿æ¥æˆåŠŸ")
        return reader
    except Exception as e:
        print(f"âŒ collector0109è¿æ¥å¤±è´¥: {e}")
        return None


def test_specific_path_direct(reader, task_type, task_id):
    """ç›´æ¥æµ‹è¯•ç‰¹å®šè·¯å¾„ä¸‹çš„æ–‡ä»¶"""
    print(f"\nğŸ” ç›´æ¥æµ‹è¯•è·¯å¾„: parse/parse/{task_type}/{task_id}/")
    print("=" * 60)
    
    try:
        container_client = reader.blob_service_client.get_container_client('parse')
        prefix = f"parse/parse/{task_type}/{task_id}/"
        print(f"  æœç´¢å‰ç¼€: {prefix}")
        
        # é™åˆ¶ç»“æœæ•°é‡ï¼Œé¿å…è¶…æ—¶
        blobs = list(container_client.list_blobs(name_starts_with=prefix, max_results=100))
        
        if blobs:
            print(f"âœ… æ‰¾åˆ° {len(blobs)} ä¸ªæ–‡ä»¶:")
            for i, blob in enumerate(blobs):
                print(f"  ğŸ“„ [{i+1}] {blob.name}")
                print(f"      ğŸ“Š å¤§å°: {blob.size} å­—èŠ‚")
                print(f"      ğŸ“… ä¿®æ”¹: {blob.last_modified}")
                print()
                
                # åªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶ï¼Œé¿å…è¾“å‡ºè¿‡å¤š
                if i >= 9:
                    if len(blobs) > 10:
                        print(f"  ... è¿˜æœ‰ {len(blobs) - 10} ä¸ªæ–‡ä»¶")
                    break
        else:
            print("âŒ æœªæ‰¾åˆ°æ–‡ä»¶")
            
        return blobs
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç‰¹å®šè·¯å¾„å¤±è´¥: {e}")
        return []


def test_path_variations_focused(reader, task_type, task_id):
    """æµ‹è¯•ä¸åŒçš„è·¯å¾„å˜ä½“ï¼ˆé™åˆ¶ç»“æœï¼‰"""
    print(f"\nğŸ” æµ‹è¯•è·¯å¾„å˜ä½“ï¼ˆé™åˆ¶ç»“æœï¼‰")
    print("=" * 60)
    
    path_variations = [
        f"parse/parse/{task_type}/{task_id}/",
        f"parse/parse/{task_type}/{task_id}",
        f"parse/{task_type}/{task_id}/",
        f"parse/{task_type}/{task_id}",
    ]
    
    container_client = reader.blob_service_client.get_container_client('parse')
    results = {}
    
    for prefix in path_variations:
        try:
            blobs = list(container_client.list_blobs(name_starts_with=prefix, max_results=5))
            results[prefix] = blobs
            print(f"  è·¯å¾„: {prefix}")
            print(f"  ç»“æœ: {len(blobs)} ä¸ªæ–‡ä»¶")
            if blobs:
                for blob in blobs[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"    ğŸ“„ {blob.name}")
            print()
        except Exception as e:
            print(f"  è·¯å¾„: {prefix} - é”™è¯¯: {e}")
            results[prefix] = []
    
    return results


def test_existing_method(reader, task_type, task_id):
    """æµ‹è¯•ç°æœ‰çš„list_parse_filesæ–¹æ³•"""
    print(f"\nğŸ” æµ‹è¯•ç°æœ‰çš„list_parse_filesæ–¹æ³•")
    print("=" * 60)
    
    try:
        files = reader.list_parse_files(task_type, task_id)
        
        if files:
            print(f"âœ… ç°æœ‰æ–¹æ³•æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
            for i, file_info in enumerate(files):
                print(f"  ğŸ“„ [{i+1}] {file_info['name']}")
                print(f"      ğŸ“Š å¤§å°: {file_info['size']} å­—èŠ‚")
                print(f"      ğŸ“… ä¿®æ”¹: {file_info['last_modified']}")
                print()
                
                # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                if i >= 4:
                    if len(files) > 5:
                        print(f"  ... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶")
                    break
        else:
            print("âŒ ç°æœ‰æ–¹æ³•æœªæ‰¾åˆ°æ–‡ä»¶")
            
        return files
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç°æœ‰æ–¹æ³•å¤±è´¥: {e}")
        return []


def test_sample_file_download(reader, task_type, task_id, blobs):
    """æµ‹è¯•ä¸‹è½½ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶"""
    if not blobs:
        print("\nâŒ æ²¡æœ‰æ–‡ä»¶å¯ä¾›ä¸‹è½½æµ‹è¯•")
        return
        
    print(f"\nğŸ” æµ‹è¯•ä¸‹è½½ç¤ºä¾‹æ–‡ä»¶")
    print("=" * 60)
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œä¸‹è½½æµ‹è¯•
    sample_blob = blobs[0]
    print(f"  é€‰æ‹©æ–‡ä»¶: {sample_blob.name}")
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("data/test_output")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ–‡ä»¶å
        file_name = Path(sample_blob.name).name
        output_path = output_dir / file_name
        
        # ä¸‹è½½æ–‡ä»¶
        container_client = reader.blob_service_client.get_container_client('parse')
        blob_client = container_client.get_blob_client(sample_blob.name)
        
        with open(output_path, 'wb') as f:
            download_stream = blob_client.download_blob()
            f.write(download_stream.readall())
        
        print(f"âœ… æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {output_path}")
        print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size} å­—èŠ‚")
        
        # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹çš„å‰å‡ è¡Œï¼ˆå¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼‰
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                content = f.read(500)  # è¯»å–å‰500ä¸ªå­—ç¬¦
                print(f"   æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
                print("   " + "-" * 40)
                for line in content.split('\n')[:5]:  # æ˜¾ç¤ºå‰5è¡Œ
                    print(f"   {line}")
                if len(content) >= 500:
                    print("   ...")
                print("   " + "-" * 40)
        except:
            print("   æ–‡ä»¶å†…å®¹æ— æ³•ä»¥æ–‡æœ¬å½¢å¼æ˜¾ç¤ºï¼ˆå¯èƒ½æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼‰")
            
        return output_path
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        return None


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª collector0109 å­˜å‚¨è´¦æˆ·ä¸“é¡¹æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•å‚æ•°
    task_type = "AmazonReviewStarJob"
    task_id = "1910598939612549120"
    
    print(f"ç›®æ ‡ä»»åŠ¡ç±»å‹: {task_type}")
    print(f"ç›®æ ‡ä»»åŠ¡ID: {task_id}")
    print(f"é¢„æœŸè·¯å¾„: parse/parse/{task_type}/{task_id}/")
    
    # 1. æµ‹è¯•è¿æ¥
    reader = test_collector0109_connection()
    if not reader:
        return
    
    # 2. æµ‹è¯•ç°æœ‰æ–¹æ³•
    existing_files = test_existing_method(reader, task_type, task_id)
    
    # 3. ç›´æ¥æµ‹è¯•ç‰¹å®šè·¯å¾„
    direct_blobs = test_specific_path_direct(reader, task_type, task_id)
    
    # 4. æµ‹è¯•è·¯å¾„å˜ä½“
    path_results = test_path_variations_focused(reader, task_type, task_id)
    
    # 5. å¦‚æœæ‰¾åˆ°æ–‡ä»¶ï¼Œæµ‹è¯•ä¸‹è½½
    if direct_blobs:
        test_sample_file_download(reader, task_type, task_id, direct_blobs)
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print(f"ç›®æ ‡è·¯å¾„: parse/parse/{task_type}/{task_id}/")
    print(f"ç°æœ‰æ–¹æ³•æ‰¾åˆ°æ–‡ä»¶æ•°: {len(existing_files)}")
    print(f"ç›´æ¥æŸ¥è¯¢æ‰¾åˆ°æ–‡ä»¶æ•°: {len(direct_blobs)}")
    
    # æ˜¾ç¤ºå„è·¯å¾„å˜ä½“çš„ç»“æœ
    print("\nğŸ¯ è·¯å¾„å˜ä½“æµ‹è¯•ç»“æœ:")
    for path, blobs in path_results.items():
        print(f"  {path}: {len(blobs)} ä¸ªæ–‡ä»¶")
    
    if direct_blobs:
        print("\nâœ… ç¡®è®¤ï¼šè¯¥è·¯å¾„ä¸‹ç¡®å®å­˜åœ¨æ–‡ä»¶ï¼")
        print("ğŸ¯ å®é™…å­˜åœ¨çš„æ–‡ä»¶:")
        for i, blob in enumerate(direct_blobs[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  ğŸ“„ {blob.name}")
        if len(direct_blobs) > 5:
            print(f"  ... è¿˜æœ‰ {len(direct_blobs) - 5} ä¸ªæ–‡ä»¶")
    else:
        print("\nâŒ è¯¥è·¯å¾„ä¸‹æœªæ‰¾åˆ°æ–‡ä»¶")


if __name__ == '__main__':
    main() 