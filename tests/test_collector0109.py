#!/usr/bin/env python3
"""
collector0109 å­˜å‚¨è´¦æˆ·å•å…ƒæµ‹è¯•
ä¸“é—¨æµ‹è¯•è§£ææ–‡ä»¶è¯»å–åŠŸèƒ½
"""
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from src.azure_resource_reader import AzureResourceReader
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_collector0109_connection():
    """æµ‹è¯•collector0109è¿æ¥"""
    print("ğŸ” æµ‹è¯•collector0109å­˜å‚¨è´¦æˆ·è¿æ¥")
    print("=" * 60)
    
    try:
        reader = AzureResourceReader('collector0109')
        print("âœ… collector0109è¿æ¥æˆåŠŸ")
        return reader
    except Exception as e:
        print(f"âŒ collector0109è¿æ¥å¤±è´¥: {e}")
        return None


def test_list_container_contents(reader):
    """æµ‹è¯•åˆ—å‡ºå®¹å™¨å†…å®¹"""
    print("\nğŸ” åˆ—å‡ºparseå®¹å™¨çš„æ ¹ç›®å½•å†…å®¹")
    print("=" * 60)
    
    try:
        container_client = reader.blob_service_client.get_container_client('parse')
        
        # åˆ—å‡ºæ ¹ç›®å½•å†…å®¹ï¼ˆé™åˆ¶50ä¸ªï¼‰
        blobs = list(container_client.list_blobs(name_starts_with='parse/', max_results=50))
        
        print(f"âœ… æ‰¾åˆ° {len(blobs)} ä¸ªæ–‡ä»¶/ç›®å½•")
        for blob in blobs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  ğŸ“„ {blob.name}")
            print(f"     ğŸ“Š å¤§å°: {blob.size} å­—èŠ‚")
            print(f"     ğŸ“… ä¿®æ”¹: {blob.last_modified}")
            print()
            
        return blobs
    except Exception as e:
        print(f"âŒ åˆ—å‡ºå®¹å™¨å†…å®¹å¤±è´¥: {e}")
        return []


def test_specific_path(reader, task_type, task_id):
    """æµ‹è¯•ç‰¹å®šè·¯å¾„ä¸‹çš„æ–‡ä»¶"""
    print(f"\nğŸ” æµ‹è¯•ç‰¹å®šè·¯å¾„: parse/parse/{task_type}/{task_id}/")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨ç°æœ‰çš„æ–¹æ³•åˆ—å‡ºæ–‡ä»¶
        files = reader.list_parse_files(task_type, task_id)
        
        if files:
            print(f"âœ… æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶:")
            for file_info in files:
                print(f"  ğŸ“„ æ–‡ä»¶: {file_info['name']}")
                print(f"     ğŸ“Š å¤§å°: {file_info['size']} å­—èŠ‚")
                print(f"     ğŸ“… ä¿®æ”¹: {file_info['last_modified']}")
                print()
        else:
            print("âŒ æœªæ‰¾åˆ°æ–‡ä»¶")
            
        # ç›´æ¥ä½¿ç”¨container clientæµ‹è¯•
        print(f"\nğŸ” ç›´æ¥æµ‹è¯•è·¯å¾„å‰ç¼€:")
        container_client = reader.blob_service_client.get_container_client('parse')
        prefix = f"parse/parse/{task_type}/{task_id}/"
        print(f"  å‰ç¼€: {prefix}")
        
        direct_blobs = list(container_client.list_blobs(name_starts_with=prefix))
        
        if direct_blobs:
            print(f"âœ… ç›´æ¥æŸ¥è¯¢æ‰¾åˆ° {len(direct_blobs)} ä¸ªæ–‡ä»¶:")
            for blob in direct_blobs:
                print(f"  ğŸ“„ ç›´æ¥æŸ¥è¯¢: {blob.name}")
                print(f"     ğŸ“Š å¤§å°: {blob.size} å­—èŠ‚")
                print(f"     ğŸ“… ä¿®æ”¹: {blob.last_modified}")
                print()
        else:
            print("âŒ ç›´æ¥æŸ¥è¯¢ä¹Ÿæœªæ‰¾åˆ°æ–‡ä»¶")
            
        return files, direct_blobs
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•ç‰¹å®šè·¯å¾„å¤±è´¥: {e}")
        return [], []


def test_path_variations(reader, task_type, task_id):
    """æµ‹è¯•ä¸åŒçš„è·¯å¾„å˜ä½“"""
    print(f"\nğŸ” æµ‹è¯•è·¯å¾„å˜ä½“")
    print("=" * 60)
    
    path_variations = [
        f"parse/parse/{task_type}/{task_id}/",
        f"parse/parse/{task_type}/{task_id}",
        f"parse/{task_type}/{task_id}/",
        f"parse/{task_type}/{task_id}",
        f"{task_type}/{task_id}/",
        f"{task_type}/{task_id}",
    ]
    
    container_client = reader.blob_service_client.get_container_client('parse')
    
    for prefix in path_variations:
        try:
            blobs = list(container_client.list_blobs(name_starts_with=prefix, max_results=10))
            print(f"  è·¯å¾„: {prefix}")
            print(f"  ç»“æœ: {len(blobs)} ä¸ªæ–‡ä»¶")
            if blobs:
                for blob in blobs[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"    ğŸ“„ {blob.name}")
            print()
        except Exception as e:
            print(f"  è·¯å¾„: {prefix} - é”™è¯¯: {e}")


def test_search_task_files(reader, task_id):
    """æœç´¢åŒ…å«ç‰¹å®štask_idçš„æ‰€æœ‰æ–‡ä»¶"""
    print(f"\nğŸ” æœç´¢åŒ…å«task_id {task_id}çš„æ‰€æœ‰æ–‡ä»¶")
    print("=" * 60)
    
    try:
        container_client = reader.blob_service_client.get_container_client('parse')
        
        # æœç´¢æ‰€æœ‰åŒ…å«task_idçš„æ–‡ä»¶
        all_blobs = container_client.list_blobs(name_starts_with='parse/')
        
        matching_blobs = []
        for blob in all_blobs:
            if task_id in blob.name:
                matching_blobs.append(blob)
                
        if matching_blobs:
            print(f"âœ… æ‰¾åˆ° {len(matching_blobs)} ä¸ªåŒ…å«task_idçš„æ–‡ä»¶:")
            for blob in matching_blobs:
                print(f"  ğŸ“„ {blob.name}")
                print(f"     ğŸ“Š å¤§å°: {blob.size} å­—èŠ‚")
                print(f"     ğŸ“… ä¿®æ”¹: {blob.last_modified}")
                print()
        else:
            print(f"âŒ æœªæ‰¾åˆ°åŒ…å«task_id {task_id}çš„æ–‡ä»¶")
            
        return matching_blobs
        
    except Exception as e:
        print(f"âŒ æœç´¢task_idæ–‡ä»¶å¤±è´¥: {e}")
        return []


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª collector0109 å­˜å‚¨è´¦æˆ·å•å…ƒæµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•å‚æ•°
    task_type = "AmazonReviewStarJob"
    task_id = "1910598939612549120"
    
    # 1. æµ‹è¯•è¿æ¥
    reader = test_collector0109_connection()
    if not reader:
        return
    
    # 2. åˆ—å‡ºå®¹å™¨å†…å®¹
    test_list_container_contents(reader)
    
    # 3. æµ‹è¯•ç‰¹å®šè·¯å¾„
    files, direct_blobs = test_specific_path(reader, task_type, task_id)
    
    # 4. æµ‹è¯•è·¯å¾„å˜ä½“
    test_path_variations(reader, task_type, task_id)
    
    # 5. æœç´¢task_idç›¸å…³æ–‡ä»¶
    matching_blobs = test_search_task_files(reader, task_id)
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print(f"ç›®æ ‡è·¯å¾„: parse/parse/{task_type}/{task_id}/")
    print(f"ç°æœ‰æ–¹æ³•æ‰¾åˆ°æ–‡ä»¶æ•°: {len(files)}")
    print(f"ç›´æ¥æŸ¥è¯¢æ‰¾åˆ°æ–‡ä»¶æ•°: {len(direct_blobs)}")
    print(f"åŒ…å«task_idçš„æ–‡ä»¶æ•°: {len(matching_blobs)}")
    
    if matching_blobs:
        print("\nğŸ¯ å®é™…å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„:")
        for blob in matching_blobs:
            print(f"  ğŸ“„ {blob.name}")


if __name__ == '__main__':
    main() 