#!/usr/bin/env python3
"""
Azure Storage --with-parse æ¨¡å¼ä¼˜åŒ–ç‰ˆæœ¬
é›†æˆ analysis_response ä¼˜åŒ–åŠŸèƒ½
"""
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from src.azure_resource_reader import AzureResourceReader
import json


def process_with_parse_optimized(task_type, task_id_param, output_type, save_dir="data/output"):
    """
    ä¼˜åŒ–ç‰ˆæœ¬çš„ --with-parse å¤„ç†
    """
    print(f"ğŸ” Azure Storage èµ„æºè¯»å–å™¨ (åŸå§‹æ•°æ® + è§£ææ•°æ® - ä¼˜åŒ–ç‰ˆæœ¬)")
    print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type}")
    print(f"ğŸ“‹ è¾“å…¥å‚æ•°: {task_id_param}")
    
    # ç¬¬ä¸€æ­¥ï¼šå¤„ç†ä»»åŠ¡IDè½¬æ¢å¹¶è·å–analysis_response
    task_id = None
    analysis_response = None
    job_id = None
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆä»»åŠ¡ID
    if len(task_id_param) >= 15 and task_id_param.isdigit():
        task_id = task_id_param
        print(f"âœ… æ£€æµ‹åˆ°æœ‰æ•ˆçš„ä»»åŠ¡ID: {task_id}")
    else:
        # éœ€è¦è½¬æ¢
        job_id = task_id_param
        if job_id.isdigit():
            job_id = f"SL{job_id}"
            print(f"ğŸ”„ æ·»åŠ SLå‰ç¼€: {job_id}")
        
        print(f"ğŸ” æŸ¥è¯¢æ•°æ®åº“è½¬æ¢ job_id: {job_id}")
        
        # å°è¯•ä½¿ç”¨ä¼˜åŒ–å™¨
        try:
            from src.azure_resource_reader_optimizer import convert_job_id_to_task_info
            task_info = convert_job_id_to_task_info(job_id)
            
            if task_info is None:
                print(f"âŒ æ— æ³•æ‰¾åˆ°å¯¹åº”çš„ä»»åŠ¡ID")
                return
            
            task_id, analysis_response = task_info
            print(f"âœ… è·å¾—ä»»åŠ¡ID: {task_id}")
            
            if analysis_response:
                print(f"âœ… è·å¾— analysis_response æ•°æ®")
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨
                try:
                    from config.analysis_response_config import is_analysis_response_enabled
                    if is_analysis_response_enabled(task_type):
                        print(f"âœ… ä»»åŠ¡ç±»å‹ {task_type} å·²å¯ç”¨ analysis_response è§£æ")
                    else:
                        print(f"âš ï¸  ä»»åŠ¡ç±»å‹ {task_type} æœªå¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
                        analysis_response = None
                except ImportError:
                    print(f"âš ï¸  é…ç½®æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
                    analysis_response = None
        except ImportError:
            print(f"âš ï¸  ä¼˜åŒ–å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
            # å›é€€åˆ°åŸºç¡€æ–¹æ³• (ç®€åŒ–ç‰ˆæœ¬)
            from src.azure_resource_reader import convert_job_id_to_task_id
            task_id = convert_job_id_to_task_id(job_id)
            if not task_id:
                print(f"âŒ è½¬æ¢å¤±è´¥")
                return
    
    print(f"ğŸ“ è·¯å¾„: yiya0110/download/compress/{task_type}/{task_id}/")
    print(f"ğŸ“ è§£æ: collector0109/parse/{task_type}/{task_id}/")
    print("=" * 60)
    
    # ç¬¬äºŒæ­¥ï¼šä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–æ–¹æ³•è·å–è§£ææ–‡ä»¶
    parse_success = False
    try:
        if analysis_response:
            print(f"ğŸš€ æ­¥éª¤1: å°è¯•ä¼˜åŒ–æ–¹æ³•è·å–è§£ææ–‡ä»¶")
            
            from src.azure_resource_reader_optimizer import fetch_and_save_parse_files_optimized
            parse_reader = AzureResourceReader('collector0109')
            
            parse_result = fetch_and_save_parse_files_optimized(
                reader=parse_reader,
                task_type=task_type,
                task_id=task_id,
                save_dir=save_dir,
                decompress=True,
                job_id=job_id,
                analysis_response=analysis_response
            )
            
            if parse_result['success']:
                print(f"âœ… è§£ææ–‡ä»¶è·å–æˆåŠŸ!")
                method_name = "analysis_responseé“¾æ¥" if parse_result.get('method_used') == 'analysis_response' else "Azureå­˜å‚¨"
                print(f"ğŸ“¡ è·å–æ–¹å¼: {method_name}")
                parse_success = True
                
                for file_info in parse_result.get('files_downloaded', []):
                    print(f"  âœ… {file_info['saved_name']} ({file_info.get('size', 0)} å­—èŠ‚)")
            else:
                print(f"âŒ ä¼˜åŒ–æ–¹æ³•å¤±è´¥: {parse_result.get('error')}")
    except ImportError:
        print(f"âš ï¸  ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨")
    
    # ç¬¬ä¸‰æ­¥ï¼šè·å–åŸå§‹æ–‡ä»¶
    print(f"\nğŸ“„ æ­¥éª¤2: è·å–åŸå§‹æ–‡ä»¶")
    
    # è·å–é»˜è®¤æ–‡ä»¶åˆ—è¡¨
    if task_type == 'AmazonReviewStarJob':
        files_to_process = ['page_1.gz', 'page_2.gz', 'page_3.gz', 'page_4.gz', 'page_5.gz']
    else:
        files_to_process = ['login.gz', 'normal.gz']
    
    print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {', '.join(files_to_process)}")
    
    reader = AzureResourceReader('yiya0110')
    decompress = output_type in ['html', 'txt', 'json']
    downloaded_files = []
    
    for filename in files_to_process:
        print(f"\n  ğŸ“„ {filename}")
        content = reader.read_task_file(task_type, task_id, filename, decompress)
        
        if content is not None:
            print(f"    âœ… è¯»å–æˆåŠŸ ({len(content)} {'å­—ç¬¦' if isinstance(content, str) else 'å­—èŠ‚'})")
            
            # ç”Ÿæˆä¿å­˜æ–‡ä»¶å
            if output_type == 'html':
                save_name = f"{filename.replace('.gz', '')}.html"
            elif output_type == 'txt':
                save_name = f"{filename.replace('.gz', '')}.txt"
            elif output_type == 'json':
                save_name = f"{filename.replace('.gz', '')}.json"
            else:
                save_name = filename
            
            # ä¿å­˜æ–‡ä»¶
            local_path = f"{save_dir}/{task_type}/{task_id}/{save_name}"
            Path(local_path).parent.mkdir(parents=True, exist_ok=True)
            
            if isinstance(content, str):
                with open(local_path, 'w', encoding='utf-8') as f:
                    f.write(content)
            else:
                with open(local_path, 'wb') as f:
                    f.write(content)
            
            print(f"    ğŸ’¾ å·²ä¿å­˜: {local_path}")
            downloaded_files.append(filename)
        else:
            print(f"    âŒ è¯»å–å¤±è´¥")
    
    # å¦‚æœæ²¡æœ‰é€šè¿‡ä¼˜åŒ–æ–¹æ³•è·å–è§£ææ–‡ä»¶ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
    if not parse_success:
        print(f"\nğŸ”„ æ­¥éª¤3: ä¼ ç»Ÿæ–¹æ³•è·å–è§£ææ–‡ä»¶")
        
        if downloaded_files:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶æ¥è·å–è§£ææ•°æ®
            combined_content = reader.read_task_file_with_parse(task_type, task_id, downloaded_files[0], True)
            parse_content = combined_content.get('parse')
            
            if parse_content:
                print(f"âœ… è§£ææ–‡ä»¶è¯»å–æˆåŠŸ ({len(parse_content)} å­—ç¬¦)")
                
                # ä¿å­˜è§£ææ–‡ä»¶
                parse_path = f"{save_dir}/{task_type}/{task_id}/parse_result.json"
                with open(parse_path, 'w', encoding='utf-8') as f:
                    f.write(parse_content)
                print(f"ğŸ’¾ è§£ææ–‡ä»¶å·²ä¿å­˜: {parse_path}")
                parse_success = True
            else:
                print(f"âŒ è§£ææ–‡ä»¶è·å–å¤±è´¥")
    
    # ç»“æœæ€»ç»“
    print(f"\n" + "=" * 60)
    print(f"ğŸ“Š å¤„ç†ç»“æœ")
    print(f"=" * 60)
    print(f"âœ… åŸå§‹æ–‡ä»¶: {len(downloaded_files)} ä¸ª")
    print(f"âœ… è§£ææ–‡ä»¶: {'1 ä¸ª' if parse_success else '0 ä¸ª'}")
    print(f"ğŸ“‚ ä¿å­˜ç›®å½•: {save_dir}/{task_type}/{task_id}/")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Azure Storage --with-parse ä¼˜åŒ–ç‰ˆæœ¬')
    parser.add_argument('task_type', help='ä»»åŠ¡ç±»å‹')
    parser.add_argument('task_id', help='ä»»åŠ¡IDæˆ–job_id')
    parser.add_argument('output_type', choices=['html', 'txt', 'json', 'binary'], help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--save-dir', default='data/output', help='ä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    process_with_parse_optimized(
        task_type=args.task_type,
        task_id_param=args.task_id,
        output_type=args.output_type,
        save_dir=args.save_dir
    )


if __name__ == '__main__':
    main() 