#!/usr/bin/env python3
"""
PDFå†…å®¹æå–å’Œå¤„ç†å·¥å…·
"""
import os
import sys
import logging
import re
from pathlib import Path
from typing import Dict, List, Optional

import PyPDF2

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PDFProcessor:
    """PDFæ–‡æ¡£å¤„ç†å™¨"""
    
    def __init__(self, pdf_path: str):
        """
        åˆå§‹åŒ–PDFå¤„ç†å™¨
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
        """
        self.pdf_path = pdf_path
        self.text_content = ""
        self.metadata = {}
        self.page_count = 0
        
    def extract_text(self) -> bool:
        """
        æå–PDFæ–‡æœ¬å†…å®¹
        
        Returns:
            bool: æå–æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            with open(self.pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                self.page_count = len(pdf_reader.pages)
                
                # æå–å…ƒæ•°æ®
                if pdf_reader.metadata:
                    self.metadata = {
                        'title': pdf_reader.metadata.get('/Title', ''),
                        'author': pdf_reader.metadata.get('/Author', ''),
                        'subject': pdf_reader.metadata.get('/Subject', ''),
                        'creator': pdf_reader.metadata.get('/Creator', ''),
                        'producer': pdf_reader.metadata.get('/Producer', ''),
                        'creation_date': pdf_reader.metadata.get('/CreationDate', ''),
                        'modification_date': pdf_reader.metadata.get('/ModDate', '')
                    }
                
                # æå–æ–‡æœ¬å†…å®¹
                text_content = []
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text.strip():
                            text_content.append(f"\n--- ç¬¬ {page_num + 1} é¡µ ---\n")
                            text_content.append(page_text)
                    except Exception as e:
                        logger.warning(f"æå–ç¬¬ {page_num + 1} é¡µæ—¶å‡ºé”™: {str(e)}")
                        continue
                
                self.text_content = '\n'.join(text_content)
                logger.info(f"æˆåŠŸæå–PDFå†…å®¹ï¼Œå…± {self.page_count} é¡µ")
                return True
                
        except Exception as e:
            logger.error(f"æå–PDFå†…å®¹å¤±è´¥: {str(e)}")
            return False
    
    def analyze_content(self) -> Dict[str, any]:
        """
        åˆ†æPDFå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
        
        Returns:
            Dict: åˆ†æç»“æœ
        """
        if not self.text_content:
            return {}
        
        analysis = {
            'total_pages': self.page_count,
            'total_characters': len(self.text_content),
            'total_words': len(self.text_content.split()),
            'sections': [],
            'key_topics': [],
            'code_blocks': [],
            'urls': [],
            'important_concepts': []
        }
        
        # æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜ï¼ˆå‡è®¾ç« èŠ‚ä»¥æ•°å­—å¼€å¤´æˆ–å…¨å¤§å†™ï¼‰
        section_pattern = r'^(?:\d+\.|\#{1,3}|[A-Z][A-Z\s]{10,}$)'
        lines = self.text_content.split('\n')
        for line in lines:
            line = line.strip()
            if line and re.match(section_pattern, line):
                analysis['sections'].append(line)
        
        # æŸ¥æ‰¾ä»£ç å—ï¼ˆåŒ…å«å¸¸è§ç¼–ç¨‹å…³é”®å­—çš„è¡Œï¼‰
        code_patterns = [
            r'def\s+\w+\(',
            r'class\s+\w+',
            r'import\s+\w+',
            r'from\s+\w+\s+import',
            r'pip\s+install',
            r'azure\.',
            r'\.py$',
            r'python\s+'
        ]
        
        for line in lines:
            line = line.strip()
            for pattern in code_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    analysis['code_blocks'].append(line)
                    break
        
        # æŸ¥æ‰¾URL
        url_pattern = r'https?://[^\s<>"{}|\\^`[\]]+'
        urls = re.findall(url_pattern, self.text_content)
        analysis['urls'] = list(set(urls))
        
        # æŸ¥æ‰¾Azureç›¸å…³çš„é‡è¦æ¦‚å¿µ
        azure_concepts = [
            'Azure Functions', 'Azure App Service', 'Azure Storage', 'Azure SQL',
            'Azure Cosmos DB', 'Azure Service Bus', 'Azure Event Hub', 'Azure Key Vault',
            'Azure Active Directory', 'Azure DevOps', 'Azure CLI', 'ARM Templates',
            'Deployment', 'Authentication', 'Authorization', 'Monitoring', 'Logging',
            'Scaling', 'Performance', 'Security', 'Best Practices'
        ]
        
        for concept in azure_concepts:
            if concept.lower() in self.text_content.lower():
                analysis['important_concepts'].append(concept)
        
        return analysis
    
    def generate_summary(self, analysis: Dict[str, any]) -> str:
        """
        ç”Ÿæˆæ–‡æ¡£æ‘˜è¦
        
        Args:
            analysis: å†…å®¹åˆ†æç»“æœ
            
        Returns:
            str: æ–‡æ¡£æ‘˜è¦
        """
        summary_lines = []
        
        # åŸºæœ¬ä¿¡æ¯
        summary_lines.append("# Azure Developer Python æ–‡æ¡£æ‘˜è¦\n")
        
        if self.metadata.get('title'):
            summary_lines.append(f"**æ–‡æ¡£æ ‡é¢˜**: {self.metadata['title']}")
        if self.metadata.get('author'):
            summary_lines.append(f"**ä½œè€…**: {self.metadata['author']}")
        
        summary_lines.append(f"**é¡µæ•°**: {analysis['total_pages']} é¡µ")
        summary_lines.append(f"**å­—ç¬¦æ•°**: {analysis['total_characters']:,}")
        summary_lines.append(f"**è¯æ•°**: {analysis['total_words']:,}")
        
        # ä¸»è¦ç« èŠ‚
        if analysis['sections']:
            summary_lines.append("\n## ä¸»è¦ç« èŠ‚")
            for section in analysis['sections'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªç« èŠ‚
                summary_lines.append(f"- {section}")
        
        # é‡è¦æ¦‚å¿µ
        if analysis['important_concepts']:
            summary_lines.append("\n## æ¶‰åŠçš„Azureæ¦‚å¿µ")
            for concept in sorted(set(analysis['important_concepts'])):
                summary_lines.append(f"- {concept}")
        
        # ä»£ç ç¤ºä¾‹
        if analysis['code_blocks']:
            summary_lines.append("\n## ä»£ç ç¤ºä¾‹æ•°é‡")
            summary_lines.append(f"å‘ç° {len(analysis['code_blocks'])} ä¸ªä»£ç ç›¸å…³çš„è¡Œ")
        
        # å‚è€ƒé“¾æ¥
        if analysis['urls']:
            summary_lines.append("\n## å‚è€ƒé“¾æ¥")
            for url in analysis['urls'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé“¾æ¥
                summary_lines.append(f"- {url}")
        
        return '\n'.join(summary_lines)
    
    def extract_key_sections(self) -> Dict[str, str]:
        """
        æå–å…³é”®ç« èŠ‚å†…å®¹
        
        Returns:
            Dict: å…³é”®ç« èŠ‚å†…å®¹
        """
        sections = {}
        
        if not self.text_content:
            return sections
        
        # å®šä¹‰è¦æå–çš„å…³é”®ç« èŠ‚æ¨¡å¼
        key_sections = {
            'introduction': ['introduction', 'ç®€ä»‹', 'æ¦‚è¿°', 'overview'],
            'setup': ['setup', 'installation', 'å®‰è£…', 'é…ç½®', 'configuration'],
            'authentication': ['authentication', 'è®¤è¯', 'èº«ä»½éªŒè¯', 'auth'],
            'deployment': ['deployment', 'éƒ¨ç½²', 'deploy'],
            'best_practices': ['best practices', 'æœ€ä½³å®è·µ', 'best practice'],
            'troubleshooting': ['troubleshooting', 'æ•…éšœæ’é™¤', 'é—®é¢˜è§£å†³', 'issues'],
            'examples': ['examples', 'ç¤ºä¾‹', 'example', 'sample']
        }
        
        lines = self.text_content.split('\n')
        current_section = None
        current_content = []
        
        for line in lines:
            line_lower = line.lower().strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å…³é”®ç« èŠ‚
            for section_key, keywords in key_sections.items():
                if any(keyword in line_lower for keyword in keywords):
                    # ä¿å­˜å‰ä¸€ä¸ªç« èŠ‚
                    if current_section and current_content:
                        sections[current_section] = '\n'.join(current_content)
                    
                    # å¼€å§‹æ–°ç« èŠ‚
                    current_section = section_key
                    current_content = [line]
                    break
            else:
                # ç»§ç»­å½“å‰ç« èŠ‚
                if current_section:
                    current_content.append(line)
        
        # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content)
        
        return sections


def main():
    """ä¸»å‡½æ•°"""
    pdf_path = "docs/azure-developer-python.pdf"
    
    if not os.path.exists(pdf_path):
        print(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return
    
    print("å¼€å§‹å¤„ç†PDFæ–‡æ¡£...")
    processor = PDFProcessor(pdf_path)
    
    # æå–æ–‡æœ¬å†…å®¹
    if not processor.extract_text():
        print("æå–PDFå†…å®¹å¤±è´¥")
        return
    
    # åˆ†æå†…å®¹
    print("åˆ†ææ–‡æ¡£å†…å®¹...")
    analysis = processor.analyze_content()
    
    # ç”Ÿæˆæ‘˜è¦
    print("ç”Ÿæˆæ–‡æ¡£æ‘˜è¦...")
    summary = processor.generate_summary(analysis)
    
    # æå–å…³é”®ç« èŠ‚
    print("æå–å…³é”®ç« èŠ‚...")
    key_sections = processor.extract_key_sections()
    
    # åˆ›å»ºnotesç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    notes_dir = Path("notes")
    notes_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜æ‘˜è¦
    summary_file = notes_dir / "azure-developer-python-summary.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary)
    print(f"æ‘˜è¦å·²ä¿å­˜è‡³: {summary_file}")
    
    # ä¿å­˜å…³é”®ç« èŠ‚
    for section_name, content in key_sections.items():
        if content.strip():
            section_file = notes_dir / f"azure-{section_name}.md"
            with open(section_file, 'w', encoding='utf-8') as f:
                f.write(f"# {section_name.title()}\n\n")
                f.write(content)
            print(f"ç« èŠ‚å·²ä¿å­˜è‡³: {section_file}")
    
    # ä¿å­˜å®Œæ•´æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
    full_text_file = notes_dir / "azure-developer-python-full-text.txt"
    with open(full_text_file, 'w', encoding='utf-8') as f:
        f.write(processor.text_content)
    print(f"å®Œæ•´æ–‡æœ¬å·²ä¿å­˜è‡³: {full_text_file}")
    
    print(f"\nâœ… PDFå¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æ–‡æ¡£ç»Ÿè®¡:")
    print(f"   - é¡µæ•°: {analysis['total_pages']}")
    print(f"   - å­—ç¬¦æ•°: {analysis['total_characters']:,}")
    print(f"   - è¯æ•°: {analysis['total_words']:,}")
    print(f"   - ç« èŠ‚æ•°: {len(analysis['sections'])}")
    print(f"   - Azureæ¦‚å¿µ: {len(analysis['important_concepts'])}")


if __name__ == '__main__':
    main() 